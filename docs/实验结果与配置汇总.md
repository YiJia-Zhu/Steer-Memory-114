# 实验结果与配置汇总（截至 2025-12-16）

本文件把当前仓库里“已经存在的配置 + 已经跑出来的 outputs”做一次集中梳理，回答：

- 现在到底有哪些配置？应该用哪个？
- 已有实验结果显示了什么问题？
- 当前阶段能得出的结论是什么？
- 下一轮更建议怎么配（附推荐 YAML）？

> 说明：本汇总基于当前 `configs/` 与 `outputs/` 快照；后续如果新增运行，请以 `outputs/*/*/tables/*.csv` 为准重新更新本表。

---

## 1. outputs 概览（LATEST 指针）

以下 `outputs/<run_name>/LATEST` 记录了“该 run_name 最新一次 run_id”（用于 `--run-id latest` 或 `eval.artifact_run_dir: .../latest`）：

- `outputs/debug/LATEST` → `20251215_170622_smoke`
- `outputs/gsm8k_offline_step1/LATEST` → `20251215_200533_off1`（注意：该 run 缺少 `memory/entries.jsonl`，属于未完成离线产物）
- `outputs/gsm8k_offline_step2/LATEST` → `20251216_142612`
- `outputs/suite_tiny_arc_c/LATEST` → `20251215_182335`
- `outputs/suite_tiny_gsm8k/LATEST` → `20251215_182335`

Suite 汇总结果目录：

- `outputs/_suite/20251215_182335/tables/suite_main_results.csv`

---

## 2. 已有结果（重点看 T=256, n=100）

下面表格来自各 run 的 `tables/main_results_single.csv` + `tables/diagnostics_T256.csv`（如果存在）。

关键字段解释：

- `Δacc`：`acc(ESM) - acc(Greedy)`
- `trunc`：`finish_reason=length` 截断率（GSM8K 下 T=256 截断率很高，会显著低估“真实推理能力”；**普通数据集建议至少用 1024，最终更建议 2048；数学类通常要 4096**）
- `overhead_mean`：ESM 额外消耗的 token（来自 probing 被丢弃的分支），越大越容易把 committed tokens 挤没
- `tool_step_rate`：ESM 在控制点上选择“非 null 工具”的比例（越大越激进）

| dataset | run_name | run_id | T_max | Greedy | ESM | Δacc | trunc(G) | trunc(ESM) | overhead_mean(ESM) | tool_step_rate(ESM) | 备注 |
|---|---|---|---:|---:|---:|---:|---:|---:|---:|---:|---|
| gsm8k | suite_tiny_gsm8k | 20251215_182335 | 256 | 0.59 | 0.60 | +0.01 | 0.42 | 0.40 | 0.63 | 0.084 | 仅有非常小幅提升；截断仍高 |
| gsm8k | gsm8k_eval_ab_base | 20251216_140344 | 256 | 0.59 | 0.56 | -0.03 | 0.42 | 0.46 | 5.04 | 0.035 | 少量 probing，略退化 |
| gsm8k | gsm8k_eval_ab_tuned | 20251216_134949 | 256 | 0.59 | 0.59 | +0.00 | 0.42 | 0.42 | 0.00 | 0.000 | ESM 基本退化成 greedy（全程 null） |
| gsm8k | gsm8k_eval_step2_gated | 20251216_151521 | 256 | 0.59 | 0.59 | +0.00 | 0.42 | 0.42 | 0.00 | 0.000 | 相似度门控更严，避免退化但也没收益 |
| gsm8k | gsm8k_eval_step2_dense | 20251216_163041 | 256 | 0.59 | 0.54 | -0.05 | 0.42 | 0.48 | 16.08 | 0.363 | 仍有明显 probing 开销，导致截断上升 |
| gsm8k | gsm8k_offline_step2 | 20251216_142612 | 256 | 0.59 | 0.48 | -0.11 | 0.42 | 0.59 | 35.73 | 0.808 | 低相似度下过度用工具 + probe 吃预算，严重退化 |
| gsm8k | gsm8k_eval_ab_tuned | ab_20251215_225825 | 256 | 0.55 | 0.35 | -0.20 | 0.46 | 0.71 | 44.57 | 1.000 | 典型“probe 抢走 committed tokens → hash_rate 下降” |
| arc-c | suite_tiny_arc_c | 20251215_182335 | 256 | 0.85 | 0.85 | +0.00 | 0.00 | 0.00 | 0.63 | 0.020 | ARC-C 输出很短，ESM 影响极小 |
| arc-c | arc_c_eval_ab_tuned | tauprobe_20251215_233211 | 256 | 0.85 | 0.85 | +0.00 | 0.00 | 0.00 | 0.00 | 0.000 | ESM 退化为 null（无变化） |

> 重要提示：上面大多数 GSM8K 结果都是 `n=100` 子集，并且 `T_max=256` 截断率 ~40–70%。要做“论文主结论”，建议至少跑 `T_max>=512` 并上全量 test。

---

## 3. 离线产物统计（library / memory）

离线产物的“有效信号密度”目前很低：`advantage > 0` 的条目占比只有 2–4% 左右，且大多数条目优势为 0。

| run_dir | candidates | library | memory_entries | pos_frac | adv_p90 | adv_max | by_m（记忆覆盖的控制点） |
|---|---:|---:|---:|---:|---:|---:|---|
| `outputs/suite_tiny_gsm8k/20251215_182335` | 64 | 16 | 132 | 0.023 | 0 | 1 | m1:40,m2:40,m3:40,m4:12 |
| `outputs/gsm8k_offline_step2/20251216_142612` | 400 | 64 | 558 | 0.036 | 0 | 1 | m1:186,m2:186,m3:186 |
| `outputs/suite_tiny_arc_c/20251215_182335` | 30 | 16 | 104 | 0.019 | ~0 | ~0 | m1:100,m2:4 |

这意味着：**如果 online 没有强门控（`min_sim` / `min_entries` / `tau_null`）且 probe 开销过大（`probe_tokens`/`L`），ESM 很容易在“信号很弱的地方也去 probe”，从而吃掉 committed tokens，反而让输出更易截断。**

---

## 4. 从现有结果看出的主要问题（根因级）

1) **T=256 下 GSM8K 截断率过高**  
`trunc_rate≈0.42`（greedy）已经很高；当前实现里 probe tokens 作为固定开销不会再扣掉 `T_max`，但如果 `decode.max_new_tokens` 太小，两种方法都会更容易截断，导致抽取/判分失败。

2) **probeing 开销是主要计算开销来源**  
`online.L`/`online.probe_tokens` 过大时，总生成 token（含 probe）会显著增加，吞吐下降；建议先用小 probe（4–8）和小 L（2–4）跑通，再逐步放大。

3) **记忆信号极稀疏，Ahat 校准很差**  
memory 中 `advantage>0` 的比例只有 2–4%，且 90 分位数是 0；用 kNN 平滑后很容易出现“看起来有一点正优势，但其实是噪声”的情况。

4) **相似度门控是“开关型”行为**  
同一套离线产物下，把 `online.min_sim` 从 0.15 提到 0.25，ESM 往往直接退化为 greedy（全程 null）。说明当前 state embedding / 记忆覆盖对齐仍不足。

5) **离线产物不完整会导致 eval-only 卡住/失败**  
`outputs/gsm8k_offline_step1/20251215_200533_off1` 缺少 `memory/entries.jsonl`，但它被 `LATEST` 指向，导致 `configs/gsm8k_eval_off1_tuned.yaml` 跑到 ESM 时无法加载记忆（常见表现：greedy 完成、ESM 无输出）。

6) **旧版 budgets sweep 已移除**  
当前评测只跑单点 `T_max = decode.max_new_tokens`，不再产出 `acc_vs_budget.csv/pdf` 与 AUC。

---

## 5. 当前阶段“能写进论文”的结论（暂定）

基于当前快照（主要是 `n=100` 子集 + `T_max=256`）：

- ESM **尚未稳定优于** greedy；目前最好也只是 `+0.01` 的小提升（`suite_tiny_gsm8k`）。
- 如果不做足够强的门控（`min_sim`/`min_entries`/`tau_null`）且 probe 开销过大（`probe_tokens`/`L`），ESM **很容易退化**，主要机制是：probe 吃掉预算 → committed tokens 变少 → 输出截断 → `####` 缺失 → 抽取/判分失败。
- 当前离线记忆的优势信号 **非常稀疏**（p90=0，pos_frac≈2–4%），说明“离线产物质量/覆盖 + state embedding 对齐”是瓶颈；在产物变强之前，online 超参的最优策略往往是“更保守（更像 greedy）”。

---

## 6. 推荐配置（下一轮更建议用哪些）

为了减少“配置太多不知道用哪个”的成本，建议优先只用以下三个入口：

1) 快速 smoke：`configs/debug.yaml`  
2) 快速但更稳的 GSM8K 迭代：`configs/gsm8k_recommended_small.yaml`（新增）  
3) 论文/投稿起点：`configs/gsm8k_recommended_paper.yaml`（新增）

两份新增推荐配置的核心策略：

- GSM8K 默认用 `gsm8k_0shot_compact` 降截断风险
- 保留更多 Stage I mined pairs（含 ``right-state→null'' 条目），提高“正确态不注入”的覆盖
- 提高检索门控（`min_sim`/`min_entries`）+ 减小 probing 开销（减小 `probe_tokens` 或 `L`）
- 用 `k_retrieve` 强调近邻；用 `k_scale` 控制注入强度（最终强度是 `k_scale * Score_i * v_i`）

---

## 7. 下一轮实验建议（优先级从高到低）

1) **先把普通数据集的主评测 budget 拉到 1024/2048（数学类至少 4096）**（否则截断率过高，结论噪声太大）  
2) **补齐离线产物完整性**：确保目标 `artifact_run_dir` 下存在 `library/` + `memory/entries.jsonl`  
3) **对 `min_sim × L × probe_tokens` 做小网格**（先确保“不退化”，再争取增益）  
4) **增加 Stage I contrast 覆盖**：提高 `K` 或保证 correct/incorrect 都存在（让 key/delta 更稳定）  
5) **跨数据集验证**：先 GSM8K+SVAMP，再 ARC/OpenBookQA，最后 MATH-500/AIME（从易到难）  

---

## 8. configs 配置清单（解决“太多了不知道用哪个”）

按“用途”分组（建议优先只看“推荐/常用”三组_toggle_）：

### 8.1 推荐（新增）

- `configs/gsm8k_recommended_small.yaml`：GSM8K 小规模快速迭代（默认更保守，强调不退化）
- `configs/gsm8k_recommended_paper.yaml`：GSM8K 论文/投稿起点（更大 budget + 更完整消融）

### 8.2 常用基础

- `configs/debug.yaml`：最小 smoke（小样本 + 多 budgets + ablations）
- `configs/debug.yaml`：最小 smoke（小样本 + ablations）
- `configs/main.yaml`：主实验起点（全量/默认更慢；适合作为“最终全量”模板）

### 8.3 多数据集 suite（多 GPU，一卡一数据集进程）

- `configs/suite_tiny.yaml`：小规模 smoke suite（GSM8K + ARC-C）
- `configs/suite_tiny_eval100.yaml`：复用 suite_tiny 设置但 eval=100（方便回归）
- `configs/suite_small.yaml`：更大 suite（含 openbookqa / commonsense_qa 等），适合扩展实验

### 8.4 GSM8K 离线产物构建（offline）

- `configs/gsm8k_offline_step1.yaml`：step1 离线增强（但当前 `outputs/gsm8k_offline_step1/latest` 产物不完整，需要补跑 memory）
- `configs/gsm8k_offline_step2.yaml`：step2 离线增强（更强库 + 更严格控制点覆盖）
- `configs/gsm8k_step2_memory_T256.yaml`：只重建 Stage III memory（T_max=256，正优势过滤）
- `configs/gsm8k_step2_memory_T256_dense.yaml`：只重建 Stage III memory（T_max=256，dense/含负优势）

### 8.5 GSM8K eval-only（复用离线产物）

- `configs/gsm8k_eval_only_template.yaml`：eval-only 模板（改 `eval.artifact_run_dir` 即可做 online sweep）
- `configs/gsm8k_eval_ab_base.yaml`：A/B 基线（复用 `suite_tiny_gsm8k` 离线产物，online 更“原始”）
- `configs/gsm8k_eval_ab_tuned.yaml`：A/B tuned（`L=1 + tau_null` / 更小 `probe_tokens` 等防退化）
- `configs/gsm8k_eval_off1_tuned.yaml`：复用 step1 产物（当前 step1/latest 缺 memory，需先补齐离线）
- `configs/gsm8k_eval_step2_gated.yaml`：复用 step2 产物（更强相似度门控，常退化为 greedy 以保稳）
- `configs/gsm8k_eval_step2_dense.yaml`：复用 step2 dense memory（允许负优势；仍可能因 probe 开销退化）
- `configs/gsm8k_eval_step2_dense_alpha05.yaml`：在 dense 基础上降注入强度（`online.k_scale=0.5`，建议作为 sweep 点）

### 8.6 GSM8K online 调参（不含离线阶段）

- `configs/gsm8k_tune_esml1.yaml`：online 调参（`L=1` 等），用于快速 sweep（通常配合 `eval.artifact_run_dir` 使用）
- `configs/gsm8k_tune_esml1_debug.yaml`：更小 eval 的调参版本
- `configs/gsm8k_tune_nopro.yaml`：no-probing 变体（对照）

### 8.7 ARC-C eval-only（复用 suite 离线产物）

- `configs/arc_c_eval_ab_base.yaml` / `configs/arc_c_eval_ab_tuned.yaml`
