# 推荐配置（GSM8K，小规模快速迭代）
#
# 目标：在较小算力/较短时间内，使用“完整 CoT（更长提示、更高 token 消耗）”来观察
#  - 精度是否提升
#  - probing/steering 是否能在高开销提示下降低总消耗或提升正确率
# 同时作为后续 NeurIPS 级实验的保守起点。
#
# 运行（单卡，建议按 stage 手动跑，便于失败后续跑）：
#   CUDA_VISIBLE_DEVICES=0 conda run -n easysteer python run.py --config configs/gsm8k_recommended_small.yaml mine
#   CUDA_VISIBLE_DEVICES=0 conda run -n easysteer python run.py --config configs/gsm8k_recommended_small.yaml select
#   CUDA_VISIBLE_DEVICES=0 conda run -n easysteer python run.py --config configs/gsm8k_recommended_small.yaml memory
#   CUDA_VISIBLE_DEVICES=1 conda run -n easysteer python run.py --config configs/gsm8k_recommended_small.yaml eval
#
# Tips：
# - 如果你只想调 online 超参：先做一次离线（mine/select/memory），再复制此文件改 run_name，
#   并设置 eval.artifact_run_dir 指向 outputs/<离线run_name>/latest，然后只跑 eval。
# - 若出现大量 finish_reason=length（截断），普通任务建议 decode.max_new_tokens 至少 1024（最终更建议 2048）；
#   若想对比“紧凑提示”再自行切换到 gsm8k_0shot_compact。

seed: 0

model:
  name_or_path: "huggingface_models/Qwen2.5-7B-Instruct"
  tensor_parallel_size: 1
  enforce_eager: true
  enable_chunked_prefill: false
  dtype: "bfloat16"
  gpu_memory_utilization: 0.7
  max_model_len: 8192
  max_num_seqs: 64

task:
  data_root: "datasets"
  dataset: "gsm8k"
  train_split: "train"
  eval_split: "test"
  max_train_examples: 100
  max_eval_examples: 100
  
prompt:
  # 使用完整 0-shot CoT 提示，保留更长推理链，便于比较 token 消耗 vs 精度
  template: "gsm8k_0shot"

decode:
  temperature: 0.0
  top_p: 1.0
  # Stage III 使用 decode.max_new_tokens 作为 T_max（记忆优势计算与预算对齐）；放宽到 2048 便于观察高消耗场景
  max_new_tokens: 2048
  logprobs: 1

control_points:
  # 为了控制 Stage III 成本，此配置只在前若干段使用控制点；剩余预算会在 tail 段无工具生成
  M: 6

offline_mine:
  K: 8
  K_pos: 4
  K_neg: 4
  temperature: 0.7
  top_p: 0.95
  # 无需与 eval 的大预算完全对齐；这里覆盖前若干控制点即可（影响 library/memory 覆盖）
  max_new_tokens: 512
  eta0: 0.001
  keep_top_C: 1024
  require_correct_and_incorrect: true
  min_correct_rollouts: 1
  min_incorrect_rollouts: 1
  pos_source: "rollout_or_gold"

offline_select:
  B: 64
  lambda_diversity: 0.5
  epsilon: 0.0001
  method: "dpp"
  random_seed: 0
  # 每个 m 至少保留一些工具，避免记忆只覆盖早期控制点
  min_per_control_point: 2

offline_memory:
  normalize_keys: true

online:
  variant: "esm"
  k_retrieve: 16
  beta: 2.0
  L: 1
  probe_tokens: 8
  rho: 0.1
  # commit 阈值：不足则更偏向 null
  tau_null: 0.05
  # 检索门控：相似度/样本量不足时当作“无记忆”
  min_sim: 0.25
  min_entries: 32
  # 注入强度缩放：最终注入是 k_scale * Score_i * v_i
  k_scale: 0.5
  protocol: "P1"

eval:
  # 评测使用 decode.max_new_tokens（此配置里是 2048）。
  methods: ["greedy", "esm"]
  ablations: ["no_memory", "no_probing"]

outputs:
  root_dir: "outputs"
  run_name: "gsm8k_recommended_small"
