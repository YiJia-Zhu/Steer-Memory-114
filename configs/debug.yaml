# Debug/sanity config: small subset, cheap settings, quick iteration

seed: 0

model:
  name_or_path: "huggingface_models/Qwen2.5-7B-Instruct"
  tensor_parallel_size: 1
  enforce_eager: true
  enable_chunked_prefill: false
  dtype: "bfloat16"
  gpu_memory_utilization: 0.6

task:
  # Offline-only: do NOT download from hub
  data_root: "datasets"
  dataset: "gsm8k"
  train_split: "train"
  eval_split: "test"
  max_train_examples: 10
  max_eval_examples: 10

prompt:
  template: "gsm8k_0shot"

decode:
  temperature: 0.0
  top_p: 1.0
  max_new_tokens: 256
  logprobs: 1

control_points:
  M: 4

offline_mine:
  # Small but still tries to create a correct-vs-incorrect contrast.
  K: 4
  K_pos: 1
  K_neg: 2
  temperature: 0.7
  top_p: 0.95
  max_new_tokens: 128
  eta0: 0.001
  keep_top_C: 32
  require_correct_and_incorrect: true
  pos_source: "rollout_or_gold"

offline_select:
  B: 8
  lambda_diversity: 0.5
  epsilon: 0.0001
  method: "dpp"
  random_seed: 0

offline_memory:
  normalize_keys: true

online:
  k_retrieve: 8
  L: 2
  probe_tokens: 8
  beta: 2.0
  rho: 0.1
  k_scale: 1.0
  tau_null: 0.0
  min_sim: 0.0
  min_entries: 1
  protocol: "P1"
  variant: "esm"

eval:
  methods: ["greedy", "esm"]
  ablations: ["no_memory", "no_probing"]

outputs:
  root_dir: "outputs"
  run_name: "debug"
